# -*- coding: utf-8 -*-
"""TrumpTweets.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ewk2-HD9IHNUmT-lCjD6uF8MEkeqRcL6
"""


import torch
import io
import os
import re
from tqdm import tqdm
from transformers import GPT2Tokenizer, GPT2LMHeadModel
import numpy as np
from torch.utils.data import Dataset, DataLoader
from transformers import AdamW, get_linear_schedule_with_warmup



device = ("cuda" if torch.cuda.is_available() else 'cpu')
print('device: ', device)

models_folder = "Trained Models"
if not os.path.exists(models_folder):
    os.mkdir(models_folder)

tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')
model = GPT2LMHeadModel.from_pretrained('gpt2-medium')
model = model.to(device)

def choose_from_top(probs, n=5):
    ind = np.argpartition(probs, -n)[-n:]
    top_prob = probs[ind]
    top_prob = top_prob / np.sum(top_prob) # Normalize
    choice = np.random.choice(n, 1, p = top_prob)
    token_id = ind[choice][0]
    return int(token_id)

class Data(Dataset):
  def __init__(self):

    with open('data/TrumpTweets.txt', encoding='utf-8') as f:
      self.train_data = f.readlines()
    
    self._clean_data()
  
  def _clean_data(self):
    text_lines = self.train_data

    for i in tqdm(range(len(text_lines))):
        text_lines[i] = re.sub(r'@[a-zA-Z]+', "", text_lines[i])
        text_lines[i] = re.sub(r'https[^"]*', "", text_lines[i])
        text_lines[i] = re.sub(r'http[^"]*', "", text_lines[i])
        text_lines[i] = re.sub('([^A-Za-z])+', ' ', text_lines[i])
        text_lines[i] = '@realDonaldTrump:' + text_lines[i] + '<EOS>'

    for line in tqdm(text_lines):
        if line[:2]=='RT':
            text_lines.remove(line)
        if line == '':
            text_lines.remove(line)
    self.train_data = text_lines
    
  def __len__(self):
    return len(self.train_data)
  
  def __getitem__(self, item):
    return self.train_data[item]

BATCH_SIZE = 64
EPOCHS = 5
LEARNING_RATE = 3e-4
WARMUP_STEPS = 0
MAX_SEQ_LEN = 400

data = Data()
tweet_loader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True)

print('training on: ', device)

model.to(device)
model.train()


optimizer = AdamW(lr=LEARNING_RATE, params=model.parameters())
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps = -1)

proc_seq_count = 0
batch_count = 0
print_every = 100



for epoch in range(EPOCHS):
  print('-----------------')
  print('EPOCH', epoch + 1)
  print('-----------------')

  sum_loss = 0.0

  for idx, batch in enumerate(tweet_loader):



    tweets = torch.tensor(tokenizer.encode(batch)).unsqueeze(0).to(device)

    if tweets.numel() == 0:
      continue

    output = model(tweets, labels=tweets)
    loss, logits = output[:2]

    optimizer.zero_grad()
    loss.backward()
    sum_loss += loss.detach().data
    optimizer.step()

    if idx % print_every == 0 and idx > 0:
      print(f'=====> ({idx}/{len(tweet_loader)}) Sum loss: {sum_loss}')
      sum_loss = 0.0

prompt = "The NHS"

print(f'Tweets generated with prompt: "{prompt}"')
print('\n')

with torch.no_grad():
    output_list = []

    for tweet_idx in range(10):
    
        cur_ids = torch.tensor(tokenizer.encode(f"@realDonaldTrump: {prompt}")).unsqueeze(0).to(device)

        finished = False
        counter = 0

        while finished == False:
            outputs = model(cur_ids, labels=cur_ids)
            loss, logits = outputs[:2]
            softmax_logits = torch.softmax(logits[0,-1], dim=0)

            if counter < 3:
              n = 100
            else:
              n = 3

            next_token_id = choose_from_top(softmax_logits.to('cpu').numpy(), n=n) 
            cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim = 1) 

            if next_token_id in tokenizer.encode('<EOS>') or counter > 100:
              tweet = tokenizer.decode(list(cur_ids.squeeze().to('cpu').numpy()))
    
              tweet = re.sub('([^A-Za-z@:\.])+', ' ', tweet)

              output_list.append(tweet)
              print(tweet)
              finished = True

            counter += 1

torch.save(model.state_dict(), 'model1')

